{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import load_model\n",
    "from keras.layers import *\n",
    "from keras import Model, Sequential, Input\n",
    "from keras import optimizers\n",
    "from keras.regularizers import l2\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import pickle\n",
    "\n",
    "\n",
    "def load(filepath):\n",
    "    with open(filepath, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "dataTriple = load('obj/triplets.pkl')\n",
    "dataPairs = load('obj/pairs.pkl')\n",
    "triplets = dataTriple['triplets'] / 256.\n",
    "pairs = dataPairs['pairs'] / 256.\n",
    "samePairs = load('obj/samePairs.pkl')\n",
    "samePairs = samePairs['pairs'] / 256."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_darknet():\n",
    "    model = load_model('darknet.h5')\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "    return model\n",
    "\n",
    "def make_style_model():\n",
    "    darknet = get_darknet()\n",
    "    \n",
    "    # pretrained layers\n",
    "    inputs = darknet.layers[0].input\n",
    "    x = darknet.layers[16].output\n",
    "    \n",
    "    # new layers\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Lambda(lambda x: tf.nn.l2_normalize(x, axis=0))(x)\n",
    "    base_model = Model(inputs, x)\n",
    "    \n",
    "    # siamese networks\n",
    "    input_a = Input((256,256,3))\n",
    "    input_b = Input((256,256,3))\n",
    "    input_c = Input((256,256,3))\n",
    "    \n",
    "    encoding_a = base_model(input_a)\n",
    "    encoding_b = base_model(input_b)\n",
    "    encoding_c = base_model(input_c)\n",
    "    \n",
    "    dist_pos = Lambda(sqEucl, output_shape=(1,))([encoding_a, encoding_b])\n",
    "    dist_neg = Lambda(sqEucl, output_shape=(1,))([encoding_a, encoding_c])\n",
    "    triple_loss = Lambda(triplet_loss, output_shape=(1,))([dist_pos, dist_neg])\n",
    "    \n",
    "    triple_model = Model([input_a, input_b, input_c], triple_loss)\n",
    "    pairModel = Model([input_a, input_b], dist_pos)\n",
    "    \n",
    "    return triple_model, pairModel\n",
    "\n",
    "def triplet_loss(x):\n",
    "    return K.maximum(x[0] - x[1] + 1, 0)\n",
    "\n",
    "def sqEucl(x):\n",
    "    return K.sum(K.square(x[0] - x[1]), axis=-1, keepdims=True)\n",
    "\n",
    "def norm(x):\n",
    "    return K.sqrt(sqEucl(x))\n",
    "    \n",
    "def identity(y_true, y_pred):\n",
    "    return K.mean(K.square(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annab./anaconda3/lib/python3.6/site-packages/keras/models.py:282: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
      "Epoch 1/2\n",
      " 256/1000 [======>.......................] - ETA: 1:14 - loss: 10.5169"
     ]
    }
   ],
   "source": [
    "tripleModel, pairModel = make_style_model()\n",
    "\n",
    "sgd = optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "tripleModel.compile(optimizer=sgd, loss=identity)\n",
    "pairModel.compile(optimizer=sgd, loss=identity)\n",
    "alphas = np.zeros(triplets.shape[0])\n",
    "\n",
    "\n",
    "tripleModel.fit([triplets[:, 0], triplets[:, 1], triplets[:, 2]], alphas, epochs=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict(x, y):\n",
    "    return pairModel.predict([x, y]).ravel()\n",
    "\n",
    "for i in range(20):\n",
    "    begin = i*20\n",
    "    end = begin + 20\n",
    "    predictions = predict(pairs[begin:end,0], pairs[begin:end,1]).reshape((-1,2))\n",
    "    print(predictions.reshape((-1, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_darknet():\n",
    "    model = load_model('darknet.h5')\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "    return model\n",
    "\n",
    "def make_content_model():\n",
    "    darknet = get_darknet()\n",
    "    \n",
    "    # pretrained layers\n",
    "    inputs = darknet.layers[0].input\n",
    "    x = darknet.layers[16].output\n",
    "    \n",
    "\n",
    "    base_model = Model(inputs, x)\n",
    "    \n",
    "    # siamese networks\n",
    "    input_a = Input((256,256,3))\n",
    "    input_b = Input((256,256,3))\n",
    "\n",
    "    \n",
    "    encoding_a = base_model(input_a)\n",
    "    encoding_b = base_model(input_b)\n",
    "\n",
    "    \n",
    "    dist_pos = Lambda(sqEucl, output_shape=(1,))([encoding_a, encoding_b])\n",
    "\n",
    "    pairModel = Model([input_a, input_b], dist_pos)\n",
    "    \n",
    "    return  pairModel\n",
    "\n",
    "def triplet_loss(x):\n",
    "    return K.maximum(x[0] - x[1] + 1, 0)\n",
    "\n",
    "def sqEucl(x):\n",
    "    return K.sum(K.square(x[0] - x[1]), axis=-1, keepdims=True)\n",
    "\n",
    "def norm(x):\n",
    "    return K.sqrt(sqEucl(x))\n",
    "    \n",
    "def identity(y_true, y_pred):\n",
    "    return K.mean(K.square(y_pred))\n",
    "\n",
    "def content_loss_fail(p, x):\n",
    "#      square difference of the activation function\n",
    "    \n",
    "    # N is the number of filters (at layer l).\n",
    "#     N = p.shape[3]\n",
    "#     # M is the height times the width of the feature map (at layer l).\n",
    "#     M = p.shape[1] * p.shape[2]\n",
    "    \n",
    "#     K = (1 / (4 * N * M))\n",
    "    _, h, w, d = p.get_shape()\n",
    "    M = h.value * w.value\n",
    "    N = d.value\n",
    "    K = 1. / (2. * N**0.5 * M**0.5)\n",
    "    loss = K * tf.reduce_sum(tf.pow((x - p), 2))\n",
    "    return loss\n",
    "\n",
    "# The content loss is the (scaled, squared) Euclidean distance\n",
    "# between feature representations of the content and combination images.\n",
    "def content_loss(content, combination):\n",
    "    print(content)\n",
    "    print(combination)\n",
    "    return K.sum(K.square(combination - content))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annab./anaconda3/lib/python3.6/site-packages/keras/models.py:282: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"lambda_50_target:0\", shape=(?, ?), dtype=float32)\n",
      "Tensor(\"lambda_50/Sum:0\", shape=(?, 16, 16, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    " pairModel = make_content_model()\n",
    "\n",
    "sgd = optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "# tripleModel.compile(optimizer=sgd, loss=content_loss)\n",
    "pairModel.compile(optimizer=sgd, loss=content_loss)\n",
    "alphas = np.zeros(triplets.shape[0])\n",
    "\n",
    "\n",
    "# tripleModel.fit(, alphas, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 2, 256, 256, 3)\n",
      "(10, 2, 256, 256, 3)\n",
      "[[ 183.45896912  418.7819519 ]\n",
      " [ 579.07019043  937.59570312]\n",
      " [ 724.72094727  313.10171509]\n",
      " ..., \n",
      " [ 286.51123047  488.1796875 ]\n",
      " [ 451.91259766  479.30926514]\n",
      " [ 548.21258545  492.84646606]]\n",
      "[[ 183.45896912  418.7819519 ]\n",
      " [ 579.07019043  937.59570312]\n",
      " [ 724.72094727  313.10171509]\n",
      " ..., \n",
      " [ 286.51123047  488.1796875 ]\n",
      " [ 451.91259766  479.30926514]\n",
      " [ 548.21258545  492.84646606]]\n",
      "[[ 183.45896912  418.7819519 ]\n",
      " [ 579.07019043  937.59570312]\n",
      " [ 724.72094727  313.10171509]\n",
      " ..., \n",
      " [ 286.51123047  488.1796875 ]\n",
      " [ 451.91259766  479.30926514]\n",
      " [ 548.21258545  492.84646606]]\n",
      "[[ 183.45896912  418.7819519 ]\n",
      " [ 579.07019043  937.59570312]\n",
      " [ 724.72094727  313.10171509]\n",
      " ..., \n",
      " [ 286.51123047  488.1796875 ]\n",
      " [ 451.91259766  479.30926514]\n",
      " [ 548.21258545  492.84646606]]\n",
      "[[ 183.45896912  418.7819519 ]\n",
      " [ 579.07019043  937.59570312]\n",
      " [ 724.72094727  313.10171509]\n",
      " ..., \n",
      " [ 286.51123047  488.1796875 ]\n",
      " [ 451.91259766  479.30926514]\n",
      " [ 548.21258545  492.84646606]]\n",
      "[[ 183.45896912  418.7819519 ]\n",
      " [ 579.07019043  937.59570312]\n",
      " [ 724.72094727  313.10171509]\n",
      " ..., \n",
      " [ 286.51123047  488.1796875 ]\n",
      " [ 451.91259766  479.30926514]\n",
      " [ 548.21258545  492.84646606]]\n",
      "[[ 183.45896912  418.7819519 ]\n",
      " [ 579.07019043  937.59570312]\n",
      " [ 724.72094727  313.10171509]\n",
      " ..., \n",
      " [ 286.51123047  488.1796875 ]\n",
      " [ 451.91259766  479.30926514]\n",
      " [ 548.21258545  492.84646606]]\n",
      "[[ 183.45896912  418.7819519 ]\n",
      " [ 579.07019043  937.59570312]\n",
      " [ 724.72094727  313.10171509]\n",
      " ..., \n",
      " [ 286.51123047  488.1796875 ]\n",
      " [ 451.91259766  479.30926514]\n",
      " [ 548.21258545  492.84646606]]\n",
      "[[ 183.45896912  418.7819519 ]\n",
      " [ 579.07019043  937.59570312]\n",
      " [ 724.72094727  313.10171509]\n",
      " ..., \n",
      " [ 286.51123047  488.1796875 ]\n",
      " [ 451.91259766  479.30926514]\n",
      " [ 548.21258545  492.84646606]]\n",
      "[[ 183.45896912  418.7819519 ]\n",
      " [ 579.07019043  937.59570312]\n",
      " [ 724.72094727  313.10171509]\n",
      " ..., \n",
      " [ 286.51123047  488.1796875 ]\n",
      " [ 451.91259766  479.30926514]\n",
      " [ 548.21258545  492.84646606]]\n"
     ]
    }
   ],
   "source": [
    "# Measure of closeness the left column(positive) should be less than right (negative)\n",
    "print(pairs.shape)\n",
    "print(samePairs.shape)\n",
    "def predict(x, y):\n",
    "    return pairModel.predict([x, y]).ravel()\n",
    "\n",
    "for i in range(10):\n",
    "   \n",
    "    predictions = predict(samePairs[0:5,0], samePairs[5:10,1]).reshape((-1,2))\n",
    "    print(predictions.reshape((-1, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
